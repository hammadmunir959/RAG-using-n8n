# ============================================
# Document Intelligence - Backend Configuration
# ============================================
# Copy this file to .env and fill in your values

# ============================================
# n8n Workflow Integration (Primary)
# ============================================
# n8n server URL (use http://n8n:5678 if using docker-compose)
N8N_BASE_URL=http://localhost:5678

# Webhook IDs from your n8n workflows
N8N_UPLOAD_WEBHOOK_ID=d5f0f619-e0b4-4e7b-a9f4-d5b84d978651
N8N_CHAT_WEBHOOK_ID=66219e80-fbed-4664-a11d-4a05167fbad2
N8N_CHAT_WEBHOOK_PATH=webhook/66219e80-fbed-4664-a11d-4a05167fbad2/chat
N8N_SUMMARY_WEBHOOK_ID=

# n8n Basic Auth (if enabled)
N8N_BASIC_AUTH_USER=admin
N8N_BASIC_AUTH_PASSWORD=admin

# ============================================
# LangGraph AI Fallback (Required)
# ============================================
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Recommended: ScrapingAnt for web search when documents lack info
# Get from: https://scrapingant.com
SCRAPER_ANT_API_KEY=your_scrapingant_key_here

# ============================================
# Model Settings
# ============================================
# Production Models:
#   - llama-3.3-70b-versatile (recommended, 280 t/s)
#   - llama-3.1-8b-instant (fast, 560 t/s)
#   - openai/gpt-oss-120b (500 t/s)
#   - openai/gpt-oss-20b (fast, 1000 t/s)
# Preview Models:
#   - meta-llama/llama-4-maverick-17b-128e-instruct
#   - meta-llama/llama-4-scout-17b-16e-instruct
#   - qwen/qwen3-32b
LLM_MODEL=llama-3.3-70b-versatile

# Embedding model for document search
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================
# Database
# ============================================
# SQLite (default, good for single server)
DATABASE_URL=sqlite:///./data/app.db

# PostgreSQL (recommended for production scaling)
# DATABASE_URL=postgresql://user:password@localhost:5432/docint
